{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTQ_a5CiGHn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b376e862-04b9-47a6-ee1a-c4beda0fde8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysam in /usr/local/lib/python3.10/dist-packages (0.22.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pysam\n",
        "import pysam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "bam_reads_file = '/content/drive/My Drive/out_sort.bam'\n",
        "bam_reads_index_file = '/content/drive/My Drive/out_sort.bam.bai'\n",
        "reference_chr_file = '/content/drive/My Drive/chr1_1e6_2e6.fasta'\n",
        "raw_reads_1_file = '/content/drive/My Drive/out.bwa.read1.fastq.gz'\n",
        "raw_reads_2_file = '/content/drive/My Drive/out.bwa.read2.fastq.gz'\n",
        "snps_file = '/content/drive/My Drive/putatative_snps.tsv'\n",
        "\n",
        "snps = pd.read_csv('/content/drive/My Drive/putatative_snps.tsv', sep='\\t')\n",
        "\n",
        "snps.head()\n",
        "\n",
        "# Open BAM file\n",
        "bam_file = pysam.AlignmentFile('/content/drive/My Drive/out_sort.bam', \"rb\")\n",
        "\n",
        "# Open FASTA file (if needed for reference sequences)\n",
        "fasta_file = pysam.FastaFile('/content/drive/My Drive/chr1_1e6_2e6.fasta')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avL_QuGhbyhf",
        "outputId": "97a1f7d5-d83b-4ba0-b5d9-57b2670c4295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pysam\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    bam_reads_file = '/content/drive/My Drive/out_sort.bam'\n",
        "    snps_file = '/content/drive/My Drive/putatative_snps.tsv'\n",
        "\n",
        "    # Load SNP data\n",
        "    snps = pd.read_csv(snps_file, sep='\\t')\n",
        "\n",
        "    # Open BAM file\n",
        "    bam_file = pysam.AlignmentFile(bam_reads_file, \"rb\")\n",
        "\n",
        "    # Function to get read counts and quality scores\n",
        "    def get_read_counts_and_quality_scores(bam_file, chrom, pos):\n",
        "        n_ref = 0\n",
        "        n_alt = 0\n",
        "        qual_scores = []\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos):\n",
        "            if pileupcolumn.pos == pos-1:\n",
        "                for pileupread in pileupcolumn.pileups:\n",
        "                    if not pileupread.is_del and not pileupread.is_refskip:\n",
        "                        base = pileupread.alignment.query_sequence[pileupread.query_position]\n",
        "                        ref_base = row['ref']\n",
        "                        alt_base = row['alt']\n",
        "                        if base == ref_base:\n",
        "                            n_ref += 1\n",
        "                        elif base == alt_base:\n",
        "                            n_alt += 1\n",
        "                        qual_scores.append(pileupread.alignment.query_qualities[pileupread.query_position])\n",
        "        error_rate = np.mean([10 ** (-q / 10) for q in qual_scores]) if qual_scores else 0.01\n",
        "        return n_ref, n_alt, error_rate\n",
        "\n",
        "    # Bayesian calculation of posteriors\n",
        "    def calculate_posterior(n_ref, n_alt, ref, alt, maf, error_rate):\n",
        "        # Prior probabilities based on Hardy-Weinberg Equilibrium\n",
        "        P_AA = (1 - maf) ** 2\n",
        "        P_AB = 2 * maf * (1 - maf)\n",
        "        P_BB = maf ** 2\n",
        "\n",
        "        # Likelihoods with error rates\n",
        "        P_data_given_AA = ((1 - error_rate) ** n_ref) * (error_rate ** n_alt)\n",
        "        P_data_given_AB = 0.5 ** (n_ref + n_alt)\n",
        "        P_data_given_BB = ((1 - error_rate) ** n_alt) * (error_rate ** n_ref)\n",
        "\n",
        "        # Bayes' Theorem\n",
        "        P_data = P_data_given_AA * P_AA + P_data_given_AB * P_AB + P_data_given_BB * P_BB\n",
        "        return {\n",
        "            ref+ref: P_data_given_AA * P_AA / P_data,\n",
        "            ref+alt: P_data_given_AB * P_AB / P_data,\n",
        "            alt+alt: P_data_given_BB * P_BB / P_data\n",
        "        }\n",
        "\n",
        "    results = []\n",
        "    for index, row in snps.iterrows():\n",
        "        chrom = row['chr']\n",
        "        pos = int(row['pos'])\n",
        "        maf = row['maf'] if not pd.isna(row['maf']) else 0.5\n",
        "\n",
        "        n_ref, n_alt, error_rate = get_read_counts_and_quality_scores(bam_file, chrom, pos)\n",
        "        posteriors = calculate_posterior(n_ref, n_alt, row['ref'], row['alt'], maf, error_rate)\n",
        "        results.append({\n",
        "            'chromosome': chrom,\n",
        "            'position': pos,\n",
        "            'putative_genotype': max(posteriors, key=posteriors.get),\n",
        "            'posterior_probability': max(posteriors.values()),\n",
        "            'n_reads': n_ref + n_alt\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_csv_path = results_df.to_csv('/content/drive/My Drive/snp_caller_results9.csv', index=False)\n",
        "    print(results_df.head())\n",
        "\n",
        "    bam_file.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOxa1xpfEy9C",
        "outputId": "dc9f5e44-586c-469c-aa30-be25c2179702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "             chromosome  position putative_genotype  posterior_probability  \\\n",
            "0  chr1:1000000-2000000    172741                AA               0.902500   \n",
            "1  chr1:1000000-2000000    325026                CC               0.688900   \n",
            "2  chr1:1000000-2000000    375797                AA               0.894754   \n",
            "3  chr1:1000000-2000000    423797                TA               0.836288   \n",
            "4  chr1:1000000-2000000    518726                CG               0.501136   \n",
            "\n",
            "   n_reads  \n",
            "0        0  \n",
            "1        0  \n",
            "2        1  \n",
            "3        2  \n",
            "4        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define file paths\n",
        "    bam_reads_file = '/content/drive/My Drive/out_sort.bam'\n",
        "    snps_file = '/content/drive/My Drive/putatative_snps.tsv'\n",
        "\n",
        "    # Load SNP data from a TSV file\n",
        "    snps = pd.read_csv(snps_file, sep='\\t')\n",
        "\n",
        "    # Open the BAM file using pysam\n",
        "    bam_file = pysam.AlignmentFile(bam_reads_file, \"rb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InaUPz3vk-df",
        "outputId": "ebeb5c9c-549b-4e2a-dfa4-138ef7b141c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pysam\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "def main():\n",
        "    if len(sys.argv) != 3:\n",
        "        print(\"Usage: python snpcaller.py reads.bam metadata.tsv\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    bam_reads_file = sys.argv[1]\n",
        "    metadata_file = sys.argv[2]\n",
        "\n",
        "    snps = pd.read_csv(metadata_file, sep='\\t')\n",
        "\n",
        "    # Open the BAM file using pysam\n",
        "    bam_file = pysam.AlignmentFile(bam_reads_file, \"rb\")\n",
        "\n",
        "    # Function to extract read counts and quality scores at SNP positions\n",
        "    def get_read_counts_and_quality_scores(bam_file, chrom, pos):\n",
        "        n_ref = 0\n",
        "        n_alt = 0\n",
        "        qual_scores = []\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos):\n",
        "            if pileupcolumn.pos == pos-1:\n",
        "                for pileupread in pileupcolumn.pileups:\n",
        "                    if not pileupread.is_del and not pileupread.is_refskip:\n",
        "                        base = pileupread.alignment.query_sequence[pileupread.query_position]\n",
        "                        ref_base = row['ref']\n",
        "                        alt_base = row['alt']\n",
        "                        if base == ref_base:\n",
        "                            n_ref += 1\n",
        "                        elif base == alt_base:\n",
        "                            n_alt += 1\n",
        "                        qual_scores.append(pileupread.alignment.query_qualities[pileupread.query_position])\n",
        "        error_rate = np.mean([10 ** (-q / 10) for q in qual_scores]) if qual_scores else 0.01\n",
        "        return n_ref, n_alt, error_rate\n",
        "\n",
        "    # Calculate posterior probabilities using a Bayesian model\n",
        "    def calculate_posterior(n_ref, n_alt, ref, alt, maf, error_rate):\n",
        "        P_AA = (1 - maf) ** 2\n",
        "        P_AB = 2 * maf * (1 - maf)\n",
        "        P_BB = maf ** 2\n",
        "\n",
        "        P_data_given_AA = ((1 - error_rate) ** n_ref) * (error_rate ** n_alt)\n",
        "        P_data_given_AB = 0.5 ** (n_ref + n_alt)\n",
        "        P_data_given_BB = ((1 - error_rate) ** n_alt) * (error_rate ** n_ref)\n",
        "\n",
        "        P_data = P_data_given_AA * P_AA + P_data_given_AB * P_AB + P_data_given_BB * P_BB\n",
        "        return {\n",
        "            ref+ref: P_data_given_AA * P_AA / P_data,\n",
        "            ref+alt: P_data_given_AB * P_AB / P_data,\n",
        "            alt+alt: P_data_given_BB * P_BB / P_data\n",
        "        }\n",
        "\n",
        "    results = []\n",
        "    # Process each SNP to compute posterior probabilities\n",
        "    for index, row in snps.iterrows():\n",
        "        chrom = row['chr']\n",
        "        pos = int(row['pos'])\n",
        "        maf = row['maf'] if not pd.isna(row['maf']) else 0.5\n",
        "\n",
        "        n_ref, n_alt, error_rate = get_read_counts_and_quality_scores(bam_file, chrom, pos)\n",
        "        posteriors = calculate_posterior(n_ref, n_alt, row['ref'], row['alt'], maf, error_rate)\n",
        "        results.append({\n",
        "            'chromosome': chrom,\n",
        "            'position': pos,\n",
        "            'AA': posteriors[row['ref']+row['ref']],\n",
        "            'AB': posteriors[row['ref']+row['alt']],\n",
        "            'BB': posteriors[row['alt']+row['alt']],\n",
        "            'n_ref_reads': n_ref,\n",
        "            'n_alt_reads': n_alt\n",
        "        })\n",
        "\n",
        "    # Create a DataFrame and save the results to a CSV file\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_csv_path = '/content/drive/My Drive/snp_caller_results7.csv'\n",
        "    results_df.to_csv(results_csv_path, index=False)\n",
        "    print(results_df.head())\n",
        "\n",
        "    # Close the BAM file\n",
        "    bam_file.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wl9RkC83hgp4",
        "outputId": "a73aab19-12d7-4191-b471-949ecb7a8dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] could not open alignment file `-f`: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8451dcd8b767>\u001b[0m in \u001b[0;36m<cell line: 84>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-8451dcd8b767>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Open the BAM file using pysam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mbam_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpysam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlignmentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbam_reads_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Function to extract read counts and quality scores at SNP positions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pysam/libcalignmentfile.pyx\u001b[0m in \u001b[0;36mpysam.libcalignmentfile.AlignmentFile.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pysam/libcalignmentfile.pyx\u001b[0m in \u001b[0;36mpysam.libcalignmentfile.AlignmentFile._open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] could not open alignment file `-f`: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysam\n",
        "import pandas as pd\n",
        "\n",
        "def count_reads_at_positions(bam_file_path, positions):\n",
        "    \"\"\"\n",
        "    Count reads in a BAM file at specified positions.\n",
        "\n",
        "    Parameters:\n",
        "        bam_file_path (str): Path to the BAM file.\n",
        "        positions (list of tuples): List of tuples where each tuple is (chromosome, position).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with keys as (chromosome, position) and values as read counts.\n",
        "    \"\"\"\n",
        "    # Open the BAM file\n",
        "    bam_file = pysam.AlignmentFile(bam_file_path, \"rb\")\n",
        "    read_counts = {}\n",
        "\n",
        "    # Iterate through each specified position\n",
        "    for chrom, pos in positions:\n",
        "        count = 0\n",
        "        # Fetch reads overlapping the position (0-based indexing adjustment)\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos, truncate=True):\n",
        "            if pileupcolumn.pos == pos - 1:\n",
        "                count = pileupcolumn.nsegments\n",
        "        read_counts[(chrom, pos)] = count\n",
        "\n",
        "    # Close the BAM file\n",
        "    bam_file.close()\n",
        "    return read_counts\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    positions_to_check = [(\"chr1:1000000-2000000\", 172741), (\"chr1:1000000-2000000\", 325026), (\"chr1:1000000-2000000\", 375797)]  # Add your positions here\n",
        "\n",
        "    # Path to your BAM file\n",
        "    bam_file_path = '/content/drive/My Drive/out_sort.bam'\n",
        "\n",
        "    # Get read counts\n",
        "    counts = count_reads_at_positions(bam_file_path, positions_to_check)\n",
        "\n",
        "    # Print results\n",
        "    for pos, count in counts.items():\n",
        "        print(f\"Position {pos}: {count} reads\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDEcV_R8snxm",
        "outputId": "b07a5078-2dda-4ddd-d276-cae8a02c72cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Position ('chr1:1000000-2000000', 172741): 5 reads\n",
            "Position ('chr1:1000000-2000000', 325026): 3 reads\n",
            "Position ('chr1:1000000-2000000', 375797): 8 reads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysam\n",
        "import pandas as pd\n",
        "\n",
        "def verify_read_counts(bam_file_path, positions, ref_alt_pairs):\n",
        "    \"\"\"\n",
        "    Verifies read counts at specified positions using pysam and compares with expected counts.\n",
        "\n",
        "    Parameters:\n",
        "        bam_file_path (str): Path to the BAM file.\n",
        "        positions (list): List of positions (chromosome, position) to check.\n",
        "        ref_alt_pairs (dict): Dictionary with (chromosome, position) as key and (ref, alt) as value.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints the results directly.\n",
        "    \"\"\"\n",
        "    bam_file = pysam.AlignmentFile(bam_file_path, \"rb\")\n",
        "\n",
        "    for chrom, pos in positions:\n",
        "        n_ref, n_alt = 0, 0\n",
        "        ref, alt = ref_alt_pairs[(chrom, pos)]\n",
        "\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos, truncate=True):\n",
        "            if pileupcolumn.pos == pos - 1:\n",
        "                for pileupread in pileupcolumn.pileups:\n",
        "                    if not pileupread.is_del and not pileupread.is_refskip:\n",
        "                        base = pileupread.alignment.query_sequence[pileupread.query_position]\n",
        "                        if base == ref:\n",
        "                            n_ref += 1\n",
        "                        elif base == alt:\n",
        "                            n_alt += 1\n",
        "\n",
        "        print(f\"Position: {chrom}:{pos}, Reference (Ref): {ref}, Alternate (Alt): {alt}\")\n",
        "        print(f\"Calculated n_ref: {n_ref}, n_alt: {n_alt}\")\n",
        "        print(\"----------\")\n",
        "\n",
        "    bam_file.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    bam_path = '/content/drive/My Drive/out_sort.bam'\n",
        "    # Example data - replace with your actual data\n",
        "    positions = [(\"chr1:1000000-2000000\", 172741), (\"chr1:1000000-2000000\", 325026), (\"chr1:1000000-2000000\", 375797), (\"chr1:1000000-2000000\", 423797), (\"chr1:1000000-2000000\", 518726), (\"chr1:1000000-2000000\", 568632), (\"chr1:1000000-2000000\", 868896)]  # List of tuples (chromosome, position)\n",
        "    ref_alt_pairs = {\n",
        "        (\"chr1:1000000-2000000\", 172741): (\"A\", \"G\"),\n",
        "        (\"chr1:1000000-2000000\", 325026): (\"T\", \"C\"),\n",
        "        (\"chr1:1000000-2000000\", 375797): (\"A\", \"T\"),\n",
        "        (\"chr1:1000000-2000000\", 423797): (\"T\", \"A\"),\n",
        "        (\"chr1:1000000-2000000\", 518726): (\"C\", \"G\"),\n",
        "        (\"chr1:1000000-2000000\", 568632): (\"A\", \"T\"),\n",
        "        (\"chr1:1000000-2000000\", 868896): (\"T\", \"A\")\n",
        "\n",
        "    }\n",
        "\n",
        "    verify_read_counts(bam_path, positions, ref_alt_pairs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMR0-9m0udQz",
        "outputId": "ff48840d-3982-48d9-8a71-2f36380c3a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Position: chr1:1000000-2000000:172741, Reference (Ref): A, Alternate (Alt): G\n",
            "Calculated n_ref: 0, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:325026, Reference (Ref): T, Alternate (Alt): C\n",
            "Calculated n_ref: 0, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:375797, Reference (Ref): A, Alternate (Alt): T\n",
            "Calculated n_ref: 1, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:423797, Reference (Ref): T, Alternate (Alt): A\n",
            "Calculated n_ref: 0, n_alt: 2\n",
            "----------\n",
            "Position: chr1:1000000-2000000:518726, Reference (Ref): C, Alternate (Alt): G\n",
            "Calculated n_ref: 0, n_alt: 1\n",
            "----------\n",
            "Position: chr1:1000000-2000000:568632, Reference (Ref): A, Alternate (Alt): T\n",
            "Calculated n_ref: 0, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:868896, Reference (Ref): T, Alternate (Alt): A\n",
            "Calculated n_ref: 2, n_alt: 0\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert BAM to FASTQ\n",
        "samtools sort -n out_sort.bam -o sorted.bam\n",
        "bedtools bamtofastq -i sorted.bam -fq out_reads.fq\n",
        "\n",
        "# Index the reference genome (only needs to be done once)\n",
        "bwa index reference.fasta\n",
        "\n",
        "# Align the reads to the reference genome\n",
        "bwa mem -t 4 -M reference.fasta out_reads.fq > aligned_reads.sam\n",
        "import subprocess\n",
        "\n",
        "def run_alignment(fastq_path, reference_path, output_path):\n",
        "    # Index the reference, if not already indexed\n",
        "    subprocess.run([\"bwa\", \"index\", reference_path], check=True)\n",
        "\n",
        "    # Run the alignment\n",
        "    with open(output_path, \"w\") as output_file:\n",
        "        subprocess.run([\"bwa\", \"mem\", \"-t\", \"4\", \"-M\", reference_path, fastq_path], stdout=output_file, check=True)\n",
        "\n",
        "# Call the function\n",
        "run_alignment(\"out_reads.fq\", \"reference.fasta\", \"aligned_reads.sam\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "VHtSYjPI0Z0C",
        "outputId": "8fa1f8b4-73a4-4954-8090-1d4d2c5b3cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-27-ee4c4ff551da>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-ee4c4ff551da>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    samtools sort -n out_sort.bam -o sorted.bam\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}